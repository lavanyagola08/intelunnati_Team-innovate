The utilized model for this project is YOLOv4 (You Only Look Once version 4), an advanced object detection algorithm known for its real-time performance and accuracy. YOLOv4 strikes a balance between detection speed and precision, making it well-suited for road object detection.

The architecture of YOLOv4 consists of a modified CSPDarknet53 backbone network and a PANet neck architecture. The backbone network extracts high-level features from input images, while the PANet enables feature fusion at multiple scales, facilitating the detection of objects with varying sizes.

During training, the YOLOv4 model was trained on the COCO (Common Objects in Context) dataset. To enhance performance, techniques like mosaic data augmentation and the CIOU (Complete Intersection over Union) loss function were employed. These techniques improve accuracy and robustness, enabling the model to handle various road object detection scenarios.

For seamless integration and real-time object detection, the YOLOv4 model was combined with the OpenCV (Open Source Computer Vision) library. OpenCV provides a wide range of computer vision functions and tools, enabling efficient processing and analysis of video frames or images. This integration empowers the system to accurately detect and manipulate road objects in real-time.

The adoption of YOLOv4 and its integration with OpenCV showcase the project's commitment to achieving high-performance road object detection, contributing to the development of autonomous driving and road safety technologies.
